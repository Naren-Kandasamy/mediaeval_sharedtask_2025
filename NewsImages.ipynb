{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 512)  # Adjust input size based on your image dimensions\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Flatten before fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, text_file, image_folder, transform=None):\n",
    "        self.text_data = pd.read_csv(text_file,encoding='latin-1')\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text_data.iloc[idx]['hashvalue']\n",
    "        \n",
    "        # Check if 'img' column contains a valid string\n",
    "        img_value = self.text_data.iloc[idx]['img']\n",
    "        if pd.notna(img_value) and isinstance(img_value, str):\n",
    "            image_path = os.path.join(self.image_folder, img_value)\n",
    "            \n",
    "            # Check if the image file exists\n",
    "            if os.path.exists(image_path):\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return text, image\n",
    "            else:\n",
    "                # Handle missing image file\n",
    "                # You can return a default image or skip the sample\n",
    "                # Here, we return a default image (all zeros)\n",
    "                default_image = Image.new('RGB', (224,224), (0, 0, 0))\n",
    "                if self.transform:\n",
    "                    default_image = self.transform(default_image)\n",
    "                return text, default_image\n",
    "        else:\n",
    "            # Handle missing or invalid image path\n",
    "            # You can return a default image or skip the sample\n",
    "            # Here, we return a default image (all zeros)\n",
    "            default_image = Image.new('RGB', (224,224), (0, 0, 0))\n",
    "            if self.transform:\n",
    "                default_image = self.transform(default_image)\n",
    "            return text, default_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model, dataset, and dataloaders\n",
    "model = CNNModel()\n",
    "dataset = NewsDataset(text_file='rt-train-textImg.csv', image_folder='images-Train', transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside your training loop\n",
    "k_values = [1, 5, 10, 20, 50, 100]\n",
    "precision_at_k = {k: 0 for k in k_values}\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for text, image in train_loader:\n",
    "        labels = torch.randint(0, 2, (len(text),))\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        \n",
    "        # Convert outputs to probabilities and get predicted labels\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_labels = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "        # Compute accuracy\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += len(labels)\n",
    "\n",
    "        # Calculate Precision@K\n",
    "        for k in k_values:\n",
    "            top_k_predictions = predicted_labels.argsort(descending=True)[:k]\n",
    "            precision_at_k[k] += (labels[top_k_predictions] == 1).sum().item() / k\n",
    "\n",
    "        # Calculate loss and perform backpropagation as before\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print Precision@K\n",
    "for k, value in precision_at_k.items():\n",
    "    precision = value / total_samples\n",
    "    print(f'Precision@{k}: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Inside your training loop\n",
    "reciprocal_ranks = []\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for text, image in train_loader:\n",
    "        labels = torch.randint(0, 2, (len(text),))\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        \n",
    "        # Convert outputs to probabilities and get predicted labels\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_labels = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "        # Compute accuracy\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += len(labels)\n",
    "\n",
    "        # Calculate reciprocal rank\n",
    "        for idx, label in enumerate(labels):\n",
    "            if label == 1:\n",
    "                # The reciprocal rank is 1 / (position + 1)\n",
    "                reciprocal_rank = 1 / (predicted_labels[idx].item() + 1)\n",
    "                reciprocal_ranks.append(reciprocal_rank)\n",
    "\n",
    "        # Calculate loss and perform backpropagation as before\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print Mean Reciprocal Rank (MRR)\n",
    "mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "print(f'Mean Reciprocal Rank (MRR): {mrr:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, images):\n",
    "    # Preprocess images if needed\n",
    "    # ...\n",
    "\n",
    "    # Convert images to torch tensors\n",
    "    # Assuming 'images' is a list of PIL images\n",
    "    tensor_images = [transforms.ToTensor()(img) if not isinstance(img, torch.Tensor) else img for img in images]\n",
    "    input_tensor = torch.stack(tensor_images)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "    # Assuming a classification task where you want to get class probabilities\n",
    "    probabilities = nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "    # Get the predicted class or classes (based on your task)\n",
    "    _, predicted_classes = torch.max(probabilities, 1)\n",
    "\n",
    "    # Convert predictions to a list of strings\n",
    "    predictions = [str(pred.item()) for pred in predicted_classes]\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model, dataset, and dataloaders\n",
    "model = CNNModel()\n",
    "test_dataset = NewsDataset(text_file=\"/home/nkandasamy/Desktop/MEDIAEVAL/newsimages_25_v1.1/subset.csv\", image_folder='/home/nkandasamy/Desktop/MEDIAEVAL/newsimages_25_v1.1', transform=transform)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, images):\n",
    "    # Unpack the tuples to get the image paths\n",
    "    image_paths = [img[1] for img in images]\n",
    "\n",
    "    # Assuming 'image_paths' is a list of PIL images or tensors\n",
    "    tensor_images = [img if isinstance(img, torch.Tensor) else transforms.ToTensor()(img) for img in image_paths]\n",
    "    input_tensor = torch.stack(tensor_images)\n",
    "\n",
    "    # Assuming your model is already in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "    # Assuming 'get_prediction' takes model outputs as an argument\n",
    "    predictions = get_prediction(model, outputs, image_paths)\n",
    "\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_format_output(model, data_loader):\n",
    "    all_predictions = []\n",
    "\n",
    "    for text, image_paths in data_loader:\n",
    "        # Assuming you have a function to get predictions for each image\n",
    "        predictions = get_predictions(model, image_paths)\n",
    "\n",
    "        # Format the output for each news URL\n",
    "        news_url = text[0]  # Assuming there is one URL per batch\n",
    "        formatted_output = f\"{news_url}\\t{''.join(predictions)}\"\n",
    "\n",
    "        all_predictions.append(formatted_output)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "\n",
    "# Usage\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "predictions = predict_and_format_output(model, test_loader)\n",
    "\n",
    "# Save predictions to a file\n",
    "with open('predictions.txt', 'w') as f:\n",
    "    f.write('\\n'.join(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
